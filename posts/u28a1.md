# Unit 28 Assignment 1

## P1 -- Web architecture and components

### ISP
An internet service provider, or ISP, is an organization which 
provides internet access to it's customers. They may be a business 
or community owned, i.e. a not for profit. The ISP facilitates
connections between computers on the internet.

An ISP owns, or rents from other ISPs, the physical lines in the
ground between houses and businesses, and the ISP data centre. The ISP
data centre is linked to other ISP data centres, facilitating exchanges
data between them.

Examples of ISPs:
* Virgin Media
* British Telecom
* TalkTalk
* Sky

### Web Hosting Services
Some companies provide a service where they will deal with hardware
and software related to web hosting. The client will upload the website
code to the service, which hosts it. This reduces the workload for the
website creator, as they do not have do deal with non-site related
details like scaling hardware for user demand and changing website
support software like databases and load schedulers.

### Domain Structure
Website addresses, or domains, have a specific structure that assists in 
parsing by intermediate nodes in their route, and routing to the correct
address. A domain consists of the website name, a TLD suffix, such as 
.com or .net, and an optional prefix subdomain. Large websites offering
multiple services make extensive use of this to group their services
under one domain. As an example, google images uses:
```
www.images.google.com
```
This consists of four parts:
* www: a legacy prefix commonly used, now obsolete and not required
* images: the *images* subdomain of google.com
* google: the websites main address name
* com: the *.com* suffix, which is a key part of the websites name

### Domain Name Registrar
A domain name registrar is a company which owns and regulates the use
of domain names. They sell the domains to businesses and individuals
who wish to purchase them. The names vary in pricing based on popularity
of the name, and the domain suffix.

### World Wide Web
The world wide web is the name for the connected web pages accessible
via URLs and hyperlinks (text with an embedded URL). The world wide
web was invented at CERN by Tim Berners Lee, who used a PC as a server
to serve webpages to client computers.

The WWW is often confused for the internet, however they are different
things. The internet is the network of computers connected via standard
networking protocols. The WWW consists of the pages and files stored
on the Internet, and accessible via HTTP and HTTPS protocols.

### Web Servers
Web servers are a key part of internet infrastructure. They are computers
programmed with the purpose of storing and serving web pages to clients.
They often do not require large amounts of storage space, but are instead
optimized for CPU speed and network IO rate. These web servers can
serve hundreds of thousands of clients at any one moment, and as such
must be able to cope with the load.

### Email Servers
Another key part of web infrastructure are the servers which power 
email messages. Email is very widely used, but has a more complex
model than regular web pages. Email servers both store received emails
and act as a source for outgoing emails.

Mail servers range from a small personal use servers to large farms
used by the likes of online email providers like gmail and outlook.

### Proxy Servers
A proxy server has a simpler function than web and mail servers, but
is no less important. Instead of providing a specific service, instead
the proxy server allows a client to forward their network connection
to its own. This allows bypassing local restrictions on internet
use, either imposed by a company or government.

Proxy servers also allow access to other networks, for example a
companies internal network could be accessed from home via a proxy
server on the premises, which clients would remotely connect to.

### Browser
A web browser is used to access the web pages stored on other servers.
It accesses webpages using a HTTP connection, which is  specified by 
the user using a URL. The webserver will return a HTML page over the
connection. The browser must then render the HTML into a user viewable
page. The webpage may require embedded images, videos, or other content
be loaded too. This requires another HTTP request to be made to the
web server.

### Email
Email is a form of messaging used where plaintext or HTML documents
are sent directly to recipients, rather than being stored on a web
server and requested by a client. Email is used for a majority of 
communication between individuals for personal and business use,
although it is being partly replaced by other messaging services.

Using email requires a dedicated email server to manage ingoing and
outgoing emails. One of the advantages of email is that individuals
can have their own accounts, but share one server.

### TCP/IP
Transmission Control Protocol and Internet Protocol are used to direct
internet traffic, primarily as a lower layer of HTTP. TCP packets are
the primary method for transmitting data over networks, which use IP
to route the packets between computers.

Most high level protocols, like HTTP and FTP, use TCP/IP at a lower
level, to transmit raw data. Each TCP packet follows a strict set of
rules which specifies its structure. This contains information like
the target IP, the source IP, and the data structure of the packet.

### Application Layer Protocols
Application layer protocols are a high level way to communicate over
a network. They are usually specific to one or two special needs, and
are utilised by only a small subset of applications. They use regular
TCP/IP on the inside, but provide a more abstract interface.

Some examples of application layer protocols would be:

* HTTP: Hyper Text Transfer Protocol, used for webpages
* SMTP: Simple Mail Transfer Protocol, used for mail
* SSH: Secure Shell, a secure remote access protocol
* FTP: File Transfer Protocol, for transferring files

### Network Flow Diagram
![][image-1]


## P2 -- User and Server Side factors that influence website performance
There are several factors that can impact the performance of websites.
These can be either on the Client or the Server side. Issues on the
client must be resolved by the client, but issues on the serverside
are the responsiblity of the business.

### Clientside Factors
#### Download Speed
The easiest to diagnose clientside issue is the Downlaod speed. The
clients internet connection has a certain max bandwith. Bandwith is the
maximum amount of data able to be recieved or sent at a single time.
For large websites with lots of images and embedded content the clients
bandwith is a very large factor in website speed. The client may think
that the websites performance is due to poor optimization, but it is
actually their own low bandwith.

#### PC Performance
Another factor affecting client website performance is their own
computers performance. Rendering webpages requires CPU speed, and 
storing multiple webpages requires RAM. If the clients PC is a low
end one, it may have issues rendering the page quickly. Another issue
is that if the computer is too old it may not be albe to render certain
elements at all. For this reason the website should have special
support for older browsers.

### Serverside Factors
#### Webserver Capacity
Webservers have a limited user capacity, based on how powerful they are
and how efficient their software is. As with PC performance limiting
client download speed, the serverside must be scaled to match average
user load. As the website becomes more popular it may reach a point
where more hardware is required, and the computer can't simply be
upgraded again. Upgrading the server is known as *Vertical Scaling*.
Buying more hardware and adding more servers is known as 
*Horizontal Scaling*.

#### Available Bandwith
As with the client having an internet speed and bandwith, the server
will also have a limited connection bandwith. Typically these are much
faster and more accomodating than regular personal internet plans, but
are still not infinite and have a limited speed.

With many clients using the website the bandwith will start to max out,
and clients will have to wait to access the website, although to them
it will just seem as if the page is loading slowly. One option to
alleviate this is to optimize the page rendering, making the pages
smaller and able to be downloaded by more users at once.

#### File Types
Another factor in webpage loading is embedded content. As the content
that is embedded in the webpage is often a key part of the site, it is
usually larger in size than the rest of the site. Because of this it is
important that the file type is chosen well. This could be helped by
choosing a compressed filetype like MP3 for music, or JPEG for images.

## P3 -- Security Risks and Protection Mechanisms involved in website performance
### Risks
#### Hacking
Hacking poses a threat to the website, whereby hackers will exploit
security vulnerabilities in the site. This can be due to mistakes in
progamming, often becuase of poor programming practice. Another reason
for poorly secured software is a lack of auditing during the development
process. This is remedied by better management during making the
website.

#### Virus
If a hacker gains access to the website system they may place a virus
on the system. This would make it seem like the website is safe, but
it could actually have a virus which would slowly damage the system.
Viruses could also be placed on the website by a web crawler bot, which
would access random websites and attempt to bypass their security
using common flaws.

Viruses can be protected against using virus scanners. These will scan
newly installed software for anything suspicious.

#### Identity Theft
Once an attacker gains access to a web server they can access all the
databases stored. These might contain user data, which is confidential.
Attackers will use this data to sell for money, or extort your users
with threats to leak the data. This is best prevented against by using
regular protection from hacking, as most identity theft is caused by
first gaining access to the system.

Encrypted Databases also reduce the risk, as the attacker will not be
able to use the data they steal.

### Protection Mechanisms
#### Firewall
A firewall is software that prevents incoming connections from ports
which are not whitelisted. Firewalls are often included with an OS,
but can also be purchased or downloaded via a third party. They can
also come in the form of a hardware firewall, which are more scalable
for larger enterprise setups.

#### SSL
Secure Socket Layer, commonly known as SSL, is a suite of encryption
tools used in web browsers to connect a HTTP connection securely. This
makes a HTTP connection a HTTPS connection. SSL allows a user to use
a webpage with confirmation of privacy. Plain HTTP can be spied on by
eavesdropping on packets, whereas HTTPS cannot be inspected.

#### Passwords
If users are encouraged to keep sure passwords then the risk of attack
is significantly reduced. Strong passwords would feature symbols and
numbers in addition to lower and uppercase letters.

Often businesses will enforce a strict password policy requiring users
to have secure passwords. This also reduces the risk of a hacker 
gaining access to one computer and then using this to acquire passwords
for others.

#### Data Protection Act
The Data Protection Act ensures that Data obtained by a business must
be dealt with responsibly. 

> The Data Protection Act controls how your personal information is used by organisations, businesses or the government.
> 
> Everyone responsible for using data has to follow strict rules called data protection principles. They must make sure the information is:
> 
> used fairly and lawfully
> used for limited, specifically stated purposes
> used in a way that is adequate, relevant and not excessive
> accurate
> kept for no longer than is absolutely necessary
> handled according to peoples data protection rights
> kept safe and secure
> not transferred outside the European Economic Area without adequate protection
> 
> There is stronger legal protection for more sensitive information, such as:
> 
> ethnic background
> 
> political opinions
> religious beliefs
> health
> sexual health
> criminal records

## M1 -- Web Architecture and Data Movement
Web data is moved in new ways, since the introduction of new 
technologies have facilitated them. One of these is the so called
Web 2.0, a system of connected blogs and online applications. In this
system, users create content using web applications, which are
connected to cloud computing platforms. These applications differ from
traditional ones in that they are fully stored in the cloud, a web 2.0
concept.

Once the content is created by users, they are posted via a variety of
methods. This can include posting to blogs, either the users personally
hosted blog, or one provided via a cloud service like Blogspot. These
blogs are part of a network of connected sites, which share information
using technologies like RSS, where other users will see updates.

## D1 -- TCP/IP Model
The 4 layer TCP/IP model is a model used to formalize how the TCP/IP stack
functions. This is different from the 7 layer OSI model which deals
with the entire network stack.

### Layer 1: Network Access
The network access layer is the lowest on the TCP/IP stack. It deals
with individual signals on the wire, and on antennas for wireless
networking. This layer is not aware even of the packet structure
of the higher up levels, and instead only knows of the 1s and 0s on
wire. This is implemented as a kernel level driver, rather than in
userspace.

### Layer 2: Internet Layer
The internet layer deals with TCP packets, and packing them from the
higher levels into a form that can be sent over cables. These packets
include the source and destination IPs, and the actual fragmented
data.

The Internet layer also sets the packet on its initial route, which
will be further helped by other nodes.

### Layer 3: Transport Layer
The transport layer is responsible for keeping the connection
between the two nodes open, so that packets will not get lost upon
being sent or received due to the connection closing. The transport
layer periodically checks that the other computer still has the
connection kept alive, whilst simultaneously sending a keepalive 
signal.

### Layer 4: Application Layer
The application layer is the upper layer in the TCP model. This layer
deals with the transport of application specific data. This includes
the application protocols mentioned earlier like HTTP, FTP, SSH, and
similar.

Application layer is the highest, and interfaces with regular APIs for
programming.

[image-1]:	# "image"